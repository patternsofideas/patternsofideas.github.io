<!DOCTYPE html>
<head>
  <meta charset="utf-8"/>
  <title>More Reasons to Mistrust Correlations &mdash; Patterns of Ideas</title>

  <link type="text/css" rel="stylesheet" href="/static/sdist/e5e8436da5bd13834d31e16c0f179529.css">

  <script type="text/javascript" src="/static/sdist/c752cd137614177858641b78f67df408.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel='shortcut icon' href="/static/favicon.ico" type='image/x-icon'/>
  <style type="text/css">
   img { mix-blend-mode: multiply; }
  </style>
  <meta property="og:author" content="Samir Khan" />
  <meta property="og:title" content="More Reasons to Mistrust Correlations" />
  <meta property="og:type" content="website" />
  <meta property="og:description" content="Another caveat about interpreting correlations." />
  <meta property="og:url" content="http://localhost/posts/correlation/" />
  <meta property="og:image" content="/static/img/athena.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="More Reasons to Mistrust Correlations" />
  <meta name="twitter:description" content="Another caveat about interpreting correlations." />
  <meta name="twitter:url" content="http://localhost/posts/correlation/" />
  <meta name="twitter:image" content="/static/img/athena.png" />
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
  <div class="thearticle">

  <article>
  
    <h1>More Reasons to Mistrust Correlations</h1>
    <p id="blog-p"><span id="blogdesc" class="marginnote">
    <a href="/">home</a> ·
    
      <a href="/about/">
        about</a>
    </span></p>

    <subtitle class="sub-date">April 02, 2020 · <span
    style="font-size: 1.6rem;"><a style="border-bottom-width: 0px !important;"
    href="http://localhost/posts/correlation/">&infin;</a></span></subtitle>

    <!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>-</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p>There is a small cottage industry in statistics of dispelling myths about correlation. This is the industry that brought us the phrase “correlation is not causation,” and also the industry that let’s more avid consumers know that correlation is not a measure of independence, nor is it a measure of whether the linear model is correct, nor is it a measure of out-of-sample prediction accuracy. Earlier this year, in one of my courses, I learned about an exciting new product from this industry: <em>correlation is not a quantity that ranges from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math></em>.</p>
<p>The less provocative version: suppose you draw data <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> from a marginal distribution <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math> and data <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math> from a marginal distribution <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math> (e.g. you have a group of people and you record their income and height). Then, the maximum/minimum possible correlation between <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math> can be determined in terms of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>, and is not necessarily <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>±</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\pm 1</annotation></semantics></math> (e.g. there is a maximum/minimum possible correlation between height and income, and this maximum/minimum has nothing to do with the relationship between height and income, only with the way height is distributed in the population and the way income is distributed in the population).</p>
<p>So you could find that the correlation between height and income is 0.2 and think “oh that’s almost nothing” but really, for reasons unrelated to the connection between height and income, 0.2 is the largest possible correlation you could have gotten. Shouldn’t this change how you think about your result?</p>
<h2>1. The Frechet extremals</h2>
<p>Before trying to answer that doozy of a question, let’s do a little math.</p>
<p><strong>Theorem.</strong> <em>Suppose <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math> are random variables with marginal distribution functions <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">F(x)</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">G(y)</annotation></semantics></math> respectively. Then, for any joint distribution function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H(x,y)</annotation></semantics></math> with marginals <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>, we have <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">cor</mtext><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>∼</mo><mi>L</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>≤</mo><msub><mtext mathvariant="normal">cor</mtext><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>∼</mo><mi>H</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>≤</mo><msub><mtext mathvariant="normal">cor</mtext><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>∼</mo><mi>U</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\text{cor}_{(X,Y)\sim L}(X, Y)\leq \text{cor}_{(X,Y)\sim H}(X,Y)\leq \text{cor}_{(X,Y)\sim U}(X,Y)</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>max</mo><mo stretchy="false" form="prefix">(</mo><mi>F</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>G</mi><mo stretchy="false" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">L(x,y)=\max(F(x)+G(y)-1,0)</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>min</mo><mo stretchy="false" form="prefix">(</mo><mi>F</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>G</mi><mo stretchy="false" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">U(x,y)=\min(F(x),G(y))</annotation></semantics></math>.</em></p>
<p>These <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>U</mi><annotation encoding="application/x-tex">U</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math>, which are the maximally and minimally correlated joint distributions with a fixed marginals, are called the Frechet extremals.</p>
<p><em>Proof</em>. Assume without the loss of generality that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>,</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">X, Y</annotation></semantics></math> have variance <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>, so that <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">cor</mtext><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>∼</mo><mi>H</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>∼</mo><mi>H</mi></mrow></msub><mo stretchy="false" form="prefix">[</mo><mi>X</mi><mi>Y</mi><mo stretchy="false" form="postfix">]</mo><mo>−</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mi>X</mi><mo>∼</mo><mi>F</mi></mrow></msub><mo stretchy="false" form="prefix">[</mo><mi>X</mi><mo stretchy="false" form="postfix">]</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mi>Y</mi><mo>∼</mo><mi>G</mi></mrow></msub><mo stretchy="false" form="prefix">[</mo><mi>Y</mi><mo stretchy="false" form="postfix">]</mo><mi>.</mi></mrow><annotation encoding="application/x-tex">\text{cor}_{(X,Y)\sim H}(X,Y)=\mathbb{E}_{(X,Y)\sim H}[XY]-\mathbb{E}_{X\sim F}[X]\mathbb{E}_{Y\sim G}[Y].</annotation></semantics></math> The trick (which I got from <a href="https://projecteuclid.org/download/pdf_1/euclid.aoms/1177699260">here</a>) is to introduce an independent pair <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mi>′</mi><mo>,</mo><mi>Y</mi><mi>′</mi><mo stretchy="false" form="postfix">)</mo><mo>∼</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">(X&#39;, Y&#39;)\sim H</annotation></semantics></math>, and then write (omitting subscripts for convenience) <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mi>X</mi><mi>Y</mi><mo stretchy="false" form="postfix">]</mo><mo>−</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mi>X</mi><mo stretchy="false" form="postfix">]</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mi>Y</mi><mo stretchy="false" form="postfix">]</mo></mtd><mtd columnalign="left"><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mi>′</mi><mo>−</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mi>′</mi><mo>−</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">]</mo><mo stretchy="false" form="postfix">)</mo><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi></mrow></msub><mo>−</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi><mi>′</mi></mrow></msub><mspace width="0.167em"></mspace><mi>d</mi><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi></mrow></msub><mo>−</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi><mi>′</mi></mrow></msub><mspace width="0.167em"></mspace><mi>d</mi><mi>v</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><mo stretchy="false" form="prefix">(</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi></mrow></msub><mo>−</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi><mi>′</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi></mrow></msub><mo>−</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi><mi>′</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>u</mi><mspace width="0.167em"></mspace><mi>d</mi><mi>v</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mo stretchy="false" form="prefix">(</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi></mrow></msub><mo>−</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi><mi>′</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi></mrow></msub><mo>−</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi><mi>′</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">]</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>u</mi><mspace width="0.167em"></mspace><mi>d</mi><mi>v</mi><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align}
\mathbb{E}[XY]-\mathbb{E}[X]\mathbb{E}[Y]&amp;=\frac{1}{2}(\mathbb{E}[(X&#39;-X)(Y&#39;-Y)]),\\
&amp;=\frac{1}{2}\mathbb{E}\left[\left(\int_{-\infty}^{\infty} \mathbb{1}_{u\geq X}-\mathbb{1}_{u\geq X&#39;}\, du\right)\left(\int_{-\infty}^{\infty} \mathbb{1}_{v\geq Y}-\mathbb{1}_{v\geq Y&#39;}\, dv\right)\right],\\
&amp;=\frac{1}{2}\mathbb{E}\left[\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(\mathbb{1}_{u\geq X}-\mathbb{1}_{u\geq X&#39;})(\mathbb{1}_{v\geq Y}-\mathbb{1}_{v\geq Y&#39;})\, du\, dv\right],\\
&amp;=\frac{1}{2}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} \mathbb{E}[(\mathbb{1}_{u\geq X}-\mathbb{1}_{u\geq X&#39;})(\mathbb{1}_{v\geq Y}-\mathbb{1}_{v\geq Y&#39;})]\, du\, dv.\\
\end{align}</annotation></semantics></math></p>
<p>Because <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(X,Y)</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mi>′</mi><mo>,</mo><mi>Y</mi><mi>′</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(X&#39;, Y&#39;)</annotation></semantics></math> are independent, the integrand simplifies to <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi></mrow></msub><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi></mrow></msub><mo stretchy="false" form="postfix">]</mo><mo>−</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>u</mi><mo>≥</mo><mi>X</mi></mrow></msub><mo stretchy="false" form="postfix">]</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><msub><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mi>v</mi><mo>≥</mo><mi>Y</mi></mrow></msub><mo stretchy="false" form="postfix">]</mo><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>2</mn><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo>,</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">2(\mathbb{E}[\mathbb{1}_{u\geq X}\mathbb{1}_{v\geq Y}]-\mathbb{E}[\mathbb{1}_{u\geq X}]\mathbb{E}[\mathbb{1}_{v\geq Y}])=2(\mathbb{P}(X\leq u, Y\leq v)-\mathbb{P}(X\leq u)\mathbb{P}(Y\leq v))</annotation></semantics></math> and so we conclude that <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">cor</mtext><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>∼</mo><mi>H</mi></mrow></msub><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><msubsup><mo>∫</mo><mrow><mo>−</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mi>F</mi><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo><mi>G</mi><mo stretchy="false" form="prefix">(</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>u</mi><mspace width="0.167em"></mspace><mi>d</mi><mi>v</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">\text{cor}_{(X,Y)\sim H}(X,Y)=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} H(u,v)-F(u)G(v)\, du\, dv.</annotation></semantics></math></p>
<p>Thus, bounding the correlation under <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> reduces to bounding <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H(u,v)</annotation></semantics></math> itself. We have the naive bounds <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo>,</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>≤</mo><mo>min</mo><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo>min</mo><mo stretchy="false" form="prefix">(</mo><mi>F</mi><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>G</mi><mo stretchy="false" form="prefix">(</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>U</mi><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{P}(X\leq u, Y\leq v)\leq \min(\mathbb{P}(X\leq u), \mathbb{P}(Y\leq v))=\min(F(u), G(v))=U(u,v)</annotation></semantics></math> and <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo>,</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo>∪</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>≥</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mn>1</mn><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathbb{P}(X\leq u, Y\leq v)=\mathbb{P}(X\leq u)+\mathbb{P}(Y\leq v)-\mathbb{P}(X\leq u\cup Y\leq v)\geq \mathbb{P}(X\leq u)+\mathbb{P}(Y\leq v)-1.</annotation></semantics></math> Of course, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo>,</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mathbb{P}(X\leq u, Y\leq v)\geq 0</annotation></semantics></math> as well, and combining this with the previous display gives <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo>,</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>≥</mo><mo>max</mo><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>≤</mo><mi>u</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mo>≤</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>L</mi><mo stretchy="false" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathbb{P}(X\leq u, Y\leq v)\geq \max(0, \mathbb{P}(X\leq u)+\mathbb{P}(Y\leq v)-1)=L(u,v),</annotation></semantics></math> completing the proof.</p>
<h2>2. Practical considerations</h2>
<p>This is not a purely theoretical concern. For example, <a href="https://statistics.stanford.edu/sites/g/files/sbiybj6031/f/SIMS%2005.pdf">this paper</a> shows that data with a log-normal distribution cannot have negative correlation greater than <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>0.368</mn></mrow><annotation encoding="application/x-tex">-0.368</annotation></semantics></math>, and <a href="https://www.jstor.org/stable/2532712?seq=4#metadata_info_tab_contents">this other paper</a> has a nice table showing the bounds for several pairs of common distributions. This can happen with real data.</p>
<p>Even if it does happen though, should you care? Should you believe more in weak correlations if they are close to the possible extremes?</p>
<p>Maybe not. One way of interpreting this result is that sometimes you get a low correlation because your data aren’t linearly related and sometimes you get a low correlation because your data, by virtue of the kind of data they are, cannot be linearly related. The thing is, this second situation is still an instance of not being linearly related.</p>
<p>You can imagine the trivial case where one of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> or <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math> is constant and so the correlation is always 0. By the arguments above, you should say to yourself, “the maximum possible correlation between distributions of this kind is only 0, so my sample correlation of 0 is nothing to scoff at,” which is clearly wrong. Weakly correlated data are still only weakly correlated, regardless of what the extremal correlations are.</p>
<p>So what the extremal correlations actually tell you is something about the way in which your data are failing to be correlated, not that they seem uncorrelated but actually are. This suggests a different way of thinking about all this, which is that the extremal correlations indicate whether it might be possible to obtain stronger correlation by transforming the data. If you know your data are log-normally distributed, and you see a negative correlation of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>0.3</mn></mrow><annotation encoding="application/x-tex">-0.3</annotation></semantics></math>, and you know the extremal is only <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>0.368</mn></mrow><annotation encoding="application/x-tex">-0.368</annotation></semantics></math>, this tells you that looking at the correlation between the log-transformed data might be a good idea (as a corollary, if you’re testing for independence, then you know this transformation will give you more power). And this is kind of a nice actionable takeaway.</p>
<p>I want to conclude by admitting that although this section has the word practical in the title, I don’t think any of this will affect how I think about correlation in practice, mainly because of the points in the first paragraph. There are so many pressing first-order reasons to be skeptical of correlations that it seems almost impossible for this particular technical caveat to be the one that pushes you over edge. (Incidentally, this is probably also why this gets so little air-time. If you’re going to give people one reason to worry about correlation as a summary statistic, it should not be this one.) But sure, if you somehow encounter a correlation that you have no other reason to doubt, and know the data come from a skewed distribution, thinking in terms of these extremes might be helpful.</p>
</body>
</html>

  
  </article>

  </div>
  <div class="thefooter">
    <p>
    <br><br>Copyright, <i>2016</i></p>
  </div> <!-- footer end -->
</body>
</html>